{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл food_trucks.txt. В нём два столбца значений — количество жителей в городе и доход грузовика с уличной едой в этом городе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/z5u3bmk21knfh6a/food_trucks.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"food_trucks.txt\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(df[0])\n",
    "x0 = np.ones(x1.shape)\n",
    "y = np.array(df[1])\n",
    "X = np.array([x0, x1]).transpose()\n",
    "w = np.random.rand(1, 2).ravel()\n",
    "epochs=3\n",
    "for i in range(epochs): \n",
    "    y_hat = X @ w  # The current predicted value of Y\n",
    "    dw = # your code here\n",
    "    w = w - 1e-20*dw\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[0], X @ w)\n",
    "plt.scatter(df[0], df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналитическое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.inv(X.T@X)@X.T@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = X @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1, np.array(yhat))\n",
    "plt.scatter(x1, y, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ${\\displaystyle R^{2}}$ (Коэффициент детерминации) — это доля дисперсии объясняемая моделью "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(np.squeeze(np.array(y)), np.squeeze(np.array(yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы оптимизации\n",
    "\n",
    "Как было показано на лекции, большинство методов машинного обучения сводятся к поиску параметров, которые минимизируют ошибку на тренировочной выборке:\n",
    "$$\n",
    "\\min_{w} L(w; D)\n",
    "$$\n",
    "Здесь:\n",
    "* $D$ — размеченная обучающая выборка, $\\{x_i, y_i\\}_{i=1}^N$\n",
    "* $L$ — функция потерь\n",
    "* $w$ — настраиваемые веса алгоритма\n",
    "\n",
    "В более общем виде задачу можно записать так:\n",
    "$$\n",
    "\\min_{x} f(x)\n",
    "$$\n",
    "Здесь:\n",
    "* $x$ — вектор значений\n",
    "* $f$ — функция, принимающая вектор в качестве аргумента и выдающая числовое значение.\n",
    "\n",
    "На семинаре рассмотрим подробнее методы минимизации функции, которые рассматривались на лекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "\n",
    "Для оптимизации возьмем простую функцию $f(x) = x^3 - 2x^2 + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x ** 3 - 2*x ** 2 + 2\n",
    "df = lambda x: 3 * x ** 2 - 4 * x # производная\n",
    "x = np.linspace(-1, 2.5, 1000)\n",
    "plt.plot(x, f(x))\n",
    "plt.xlim([-1, 2.5])\n",
    "plt.ylim([0, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И определим функцию, которая будет оптимизировать функцию $f(x)$ градиентным спуском с заданным постоянным шагом (он же learning rate, темп обучения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_plot_steps(learning_rate, x_new=2, compute_learning_rate=None):\n",
    "    x_old = 0\n",
    "    # x_new — точка старта\n",
    "    eps = 0.0001\n",
    "    x_list, y_list = [x_new], [f(x_new)] # инициализируем список координат и значений функций при итерации\n",
    "    \n",
    "    # спускаемся, пока разница между координатами не достигла требуемой точности\n",
    "    i = 0\n",
    "    while abs(x_new - x_old) > eps: \n",
    "        x_old = x_new\n",
    "        # считаем направление спуска\n",
    "        direction = -df(x_old)\n",
    "        # обновляем значение темпа обучения, если нам задана функция для этого\n",
    "        if compute_learning_rate is not None:\n",
    "            learning_rate = compute_learning_rate(i, learning_rate)\n",
    "        # делаем шаг\n",
    "        x_new = x_old + learning_rate * direction\n",
    "        # запоминаем очередной шаг минимизации\n",
    "        x_list.append(x_new)\n",
    "        y_list.append(f(x_new))\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Found local min:\", x_new)\n",
    "    print(\"Steps number:\", len(x_list))\n",
    "    \n",
    "    plt.figure(figsize=[10,3])\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x, f(x), c=\"b\")\n",
    "    plt.xlim([-1,2.5])\n",
    "    plt.ylim([0,3])\n",
    "    plt.title(\"Descent trajectory\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(x_list,y_list,c=\"r\")\n",
    "    plt.plot(x_list,y_list,c=\"r\")\n",
    "    plt.plot(x,f(x), c=\"b\")\n",
    "    plt.xlim([1.2,2.1])\n",
    "    plt.ylim([0,3])\n",
    "    plt.title(\"Descent trajectory (zoomed in)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оптимизацию с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.1, x_new=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем шаг побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что, если взять 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Застопорились в нуле, т.к. нашли точный локальный максимум. В нем производная равна нулю и мы никуда не можем сдвинуться. А если взять 0.49?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что, если взять 0.51?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы улетели далеко влево. Это можно понять, распечатав значения x_new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмём маленький шаг. Например, 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.01?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше шаг, тем медленнее мы идём к минимум (и можем вдобавок застрять по пути). Чем больше темп обучения, тем большие расстояния мы перепрыгиваем (и имеем гипотетическую возможность найти минимум получше). Хорошая стратегия — начинать с достаточно большого шага (чтобы хорошо попутешествовать по функции), а потом постепенно его уменьшать, чтобы стабилизировать процесс обучения в каком-то локальном минимуме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем изменять шаг динамически:\n",
    "$lr(i + 1) = lr(i) * 0.9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_learning_rate(i, prev_lr):\n",
    "    return prev_lr * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.45, compute_learning_rate=compute_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сравнивать с постоянным темпом обучения, то мы нашли минимум в 2 раза быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это, конечно, искуственный пример, но такая же идея используются для обучения алгоритмов машинного обучения с миллионами параметров, функции потерь которых имеют очень сложную структуру и не поддаются визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Продвинутые методы оптимизации\n",
    "\n",
    "Попробуем реализовать продвинутые методы градиентного спуска!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
